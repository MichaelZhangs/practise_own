下面以一个经典的词频统计（Word Count）程序为例，学习PySpark的使用，词频统计是一个很经典的分布式程序，这里用到中文分词库jieba，去除停用词再进行计数

新建Python工程，并新建脚本wordcount.py
在网上随便找一篇新闻报道，复制内容到文本文件news.txt，记住其路径
到GitHub上搜索中文停用词资源，如从 https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt 下载得到stopwords-zh.txt
打开脚本并输入如下代码

传智教育·黑马程序员大数据开发研究院全新录制的大数据开发入门教程，相关资料源码笔记等关注微信公众号：黑马程序员，回复关键词：领取资源02
===============================
Spark是大数据体系的明星产品，是一款高性能的分布式内存迭代计算框架，可以处理海量规模的数据。本课程基于Python语言学习Spark3.2开发，课程的讲解注重理论联系实际，高效快捷，深入浅出，让初学者也能快速掌握。让有经验的工程师也能有所收获。学习完成后可以胜任高级级别的大数据相关岗位。